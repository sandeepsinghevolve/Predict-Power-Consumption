{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "simple machine learning modeling using Python scikit-learn, Pandas, and Numpy.\n",
    "\n",
    "Objective variable: KWH.\n",
    "\n",
    "Dummy variables: METROMICRO, UR, IECC_Climate_Pub\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tools.plot as plot\n",
    "import pandas as pd\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "%matplotlib inline\n",
    "FILE = 'recs2009_public.csv'\n",
    "df= pd.read_csv(FILE)\n",
    "df.head()\n",
    "# Dummy Variables\n",
    "# Dummy variables\n",
    "df_dummies =  pd.get_dummies(df)\n",
    "df_dummies.describe()\n",
    "# X and y for supervised learning\n",
    "X = df_dummies.drop(['KWH'],axis = 1)\n",
    "y = df_dummies['KWH']\n",
    "# Split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_pre, X_test_pre, y_train, y_test = train_test_split(X, y)\n",
    "# Normalization\n",
    "# Preprocessing & Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_pre)\n",
    "# Train and Test data before feature selection\n",
    "X_train_prefs = scaler.transform(X_train_pre)\n",
    "X_test_prefs = scaler.transform(X_test_pre)\n",
    "# Feature Selection\n",
    "Select useful features to speed up the training process\n",
    "### Automatic Feature Selection\n",
    "# Feature Selection\n",
    "# Automatic Fearture Selection\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "rng = np.random.RandomState(42)\n",
    "noise_train = rng.normal(size=(len(X_train_prefs), 50))\n",
    "X_train_noise = np.hstack([X_train_prefs, noise_train])\n",
    "noise_test = rng.normal(size=(len(X_test_prefs), 50))\n",
    "X_test_noise = np.hstack([X_test_prefs, noise_test])\n",
    "\n",
    "select = SelectPercentile(percentile=50)\n",
    "select.fit(X_train_noise, y_train)\n",
    "\n",
    "# transform training set\n",
    "X_train1 = select.transform(X_train_noise)\n",
    "# transform test data\n",
    "X_test1 = select.transform(X_test_noise)\n",
    "\n",
    "print(\"X_train.shape: {}\".format(X_train_noise.shape))\n",
    "print(\"X_train_selected.shape: {}\".format(X_train1.shape))\n",
    "### Random Forest Feature Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "select = SelectFromModel(RandomForestClassifier(),threshold=\"median\")\n",
    "select.fit(X_train_prefs, y_train)\n",
    "X_train2 = select.transform(X_train_prefs)\n",
    "print(\"X_train_prefs.shape: {}\".format(X_train_prefs.shape))\n",
    "print(\"X_train.shape: {}\".format(X_train2.shape))\n",
    "X_test2 = select.transform(X_test_prefs)\n",
    "### Assian Train and Test Data\n",
    "X_train = X_train2\n",
    "X_test = X_test2\n",
    "# Simple ML Regressors\n",
    "### k-neighbors regression\n",
    "# k-neighbors regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knr = KNeighborsRegressor(n_neighbors=6)\n",
    "\n",
    "visualizer1 = PredictionError(knr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()   \n",
    "visualizer2 = ResidualsPlot(knr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "visualizer1 = PredictionError(lr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()    \n",
    "visualizer2 = ResidualsPlot(lr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# Ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "rr = Ridge(alpha = 5)\n",
    "\n",
    "visualizer1 = PredictionError(rr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()  \n",
    "visualizer2 = ResidualsPlot(rr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "lsr = Lasso(alpha = 0.01, max_iter=10000)\n",
    "visualizer1 = PredictionError(lsr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()  \n",
    "visualizer2 = ResidualsPlot(lsr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor(max_depth = 5)\n",
    "\n",
    "visualizer1 = PredictionError(dtr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()  \n",
    "visualizer2 = ResidualsPlot(dtr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0,n_estimators=1000)\n",
    "\n",
    "visualizer1 = PredictionError(rfr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()  \n",
    "visualizer2 = ResidualsPlot(rfr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import SVR\n",
    "# svmr = SVR(gamma = 'scale',C = 1.0, epsilon = 0.2)\n",
    "svmr = SVR(kernel='linear', gamma='auto')\n",
    "\n",
    "visualizer1 = PredictionError(svmr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()  \n",
    "visualizer2 = ResidualsPlot(svmr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# stochastic gradient descent regressor\n",
    "from sklearn import linear_model\n",
    "sgdr = linear_model.SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\n",
    "visualizer1 = PredictionError(sgdr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()  \n",
    "visualizer2 = ResidualsPlot(sgdr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n",
    "# Shallow Neural Networks\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlpr = MLPRegressor()\n",
    "\n",
    "visualizer1 = PredictionError(mlpr)\n",
    "visualizer1.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer1.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer1.show()  \n",
    "visualizer2 = ResidualsPlot(mlpr)\n",
    "visualizer2.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer2.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer2.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
